{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ANF_DL_GalaxyGenerativeModeling:GANs.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EiffL/Tutorials/blob/master/GenerativeModels/GalaxyMorphologyGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YNYxkv19Bb3u"
      },
      "source": [
        "##### Copyright 2019-2020 Francois Lanusse.\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfcfTuBaBg5l"
      },
      "source": [
        "# Generative Modeling of Galaxy Images\n",
        "\n",
        "Author: [@EiffL](https://github.com/EiffL) (Francois Lanusse)\n",
        "\n",
        "### Overview\n",
        "\n",
        "In this tutorial, we learn how to combine Keras, TensorFlow Probability, and Google Colab to train a Generative Adversarial Network in the cloud.\n",
        "\n",
        "We will be using data from the HSC Survey, and more specifically from the Public Data Release 2, which can be found here: https://hsc-release.mtk.nao.ac.jp/doc/\n",
        "\n",
        "\n",
        "The dataset contains postage stamps of galaxies in 5 HSC bands.\n",
        "\n",
        "\n",
        "### Learning objectives\n",
        "\n",
        "In this notebook, we will learn how to:\n",
        "*   Build a tf.data.Dataset input pipeline.\n",
        "*   Build a simple convolutional generator/discriminator.\n",
        "*   Train a model with TF-GAN.\n",
        "*   Generate new pretty galaxies.\n",
        "\n",
        "### Instructions for enabling GPU access\n",
        "\n",
        "By default, notebooks are started without acceleration. To make sure that the runtime is configured for using GPUs, go to `Runtime > Change runtime type`, and select GPU in `Hardware Accelerator`.\n",
        "\n",
        "\n",
        "\n",
        "### Installs and Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "07RSU-1av8UE"
      },
      "source": [
        "!pip install --quiet tensorflow-gan"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5XIcKLGBE33"
      },
      "source": [
        "import os\n",
        "import re\n",
        "import time\n",
        "import json\n",
        "import tensorflow as tf\n",
        "import tensorflow_gan as tfgan"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OGBGfUdSF7QH"
      },
      "source": [
        "### Checking for GPU access"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jgs_ONXTF6vX"
      },
      "source": [
        "#Checking for GPU access\n",
        "if tf.test.gpu_device_name() != '/device:GPU:0':\n",
        "  print('WARNING: GPU device not found.')\n",
        "else:\n",
        "  print('SUCCESS: Found GPU: {}'.format(tf.test.gpu_device_name()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "97CFtkkqFv5P"
      },
      "source": [
        "## Downloading the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q4VyE8QmJEGh"
      },
      "source": [
        "# Google Cloud Storage bucket for Estimator logs and storing\n",
        "# the training dataset.\n",
        "bucket = 'ahw2019' # Bucket setup for this AHW2019 tutorial\n",
        "print('Using bucket: {}'.format(bucket))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57gH9b7RPWzu"
      },
      "source": [
        "# Retrieve the catalogs\n",
        "!gsutil -m cp gs://{bucket}/hsc_photoz/cat2/catalog_*.fits .\n",
        "!gsutil -m cp gs://{bucket}/hsc_photoz/tfrecords2/* ."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OGENy38rPn1s"
      },
      "source": [
        "from astropy.table import Table\n",
        "cat_train = Table.read('catalog_train.fits')\n",
        "cat_test = Table.read('catalog_test.fits')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3HRAxSC_JS3R"
      },
      "source": [
        "## Building a tf.data.Dataset Input Pipeline\n",
        "\n",
        "The first step is to read the data from the tfrecords format on disk into a tf.data.Dataset. This TensorFlow API is the canonical way to supply data to a model during training. It is fast and optimized, and supports distributed training!\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s2Nznh3aJSXa"
      },
      "source": [
        "# The data is saved as a TFRecord, needs to get parsed and turned into a dataset\n",
        "dset = tf.data.TFRecordDataset(['training-%05d-of-00010'%i for i in range(10)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JKfKNgEeNTuE"
      },
      "source": [
        "# To extract one example from the TFRecord, we can use the following syntax:\n",
        "for i in dset.take(1):\n",
        "  print(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8t0nLpgfDzV2"
      },
      "source": [
        "The data is currently stored in a serialized format, as strings. We need to decode it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yhPgF33ZOK7m"
      },
      "source": [
        "img_len = 64\n",
        "num_bands = 5\n",
        "\n",
        "# This function defines the operations to apply to a serialized example to\n",
        "# turn it back into a dictionary object\n",
        "def parse_example(example):\n",
        "\n",
        "  # First, let's define what fields we are expecting\n",
        "  data_fields = {\n",
        "      \"image/encoded\": tf.io.FixedLenFeature((), tf.string),\n",
        "      \"image/format\": tf.io.FixedLenFeature((), tf.string),\n",
        "      \"id\": tf.io.FixedLenFeature((), tf.int64)\n",
        "  }\n",
        "  for k in cat_train.colnames[5:]:\n",
        "    data_fields['attrs/'+k] = tf.io.FixedLenFeature([], tf.float32)\n",
        "\n",
        "  parsed_example = tf.io.parse_single_example(example, data_fields)\n",
        "\n",
        "  # Decode the image from string format\n",
        "  cutout = tf.io.decode_raw(parsed_example['image/encoded'], out_type=tf.float32) \n",
        "  cutout = tf.reshape(cutout, [img_len, img_len, num_bands])\n",
        "\n",
        "  # Outputs results as a dictionary\n",
        "  output_dict = {\"cutout\": cutout}\n",
        "  for k in cat_train.colnames[5:]:\n",
        "    output_dict[k] = parsed_example['attrs/'+k]\n",
        "\n",
        "  return output_dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VzMcHlasEMvF"
      },
      "source": [
        "With this decoding function defined, we can apply it to the dataset by using the dataset.map() method:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZIBewKf0ELN-"
      },
      "source": [
        "train_dset = dset.map(parse_example)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mbi4bL21EMED"
      },
      "source": [
        "Let's have a look at the content of this new dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IHcy8OgQTQMW"
      },
      "source": [
        "for i in train_dset.take(1):\n",
        "  print(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cVBQKpT7EhDa"
      },
      "source": [
        "Now our dataset is decoded into numbers and arrays."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_YYlkH3dLm_2"
      },
      "source": [
        "### Dataset preprocessing\n",
        "\n",
        "An important step of any input pipeline is to make\n",
        "sure the data is reasonably well behaved before \n",
        "feeding to the neural network. Here are some common strategies:\n",
        "\n",
        "\n",
        "*   Apply log() to values with large dynamic range\n",
        "*   Remove means, and standardize standard deviation\n",
        "*   etc...\n",
        "\n",
        "\n",
        "So, we begin by looking at our data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yHIKuq5OMa7E"
      },
      "source": [
        "# What's in our dataset:\n",
        "train_dset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9PRSqauJTt5f"
      },
      "source": [
        "Ok, we see that this dataset is a dictionary, field `inputs` are hsc cutouts in 5 bands (g,r,i,z,y), this will be the inputs to our CNN. We also see a `specz_redshift` entry, that will be our prediction target. Let's have a look at these."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xm0ifpc4VrYc"
      },
      "source": [
        "from astropy.visualization import make_lupton_rgb\n",
        "%pylab inline \n",
        "\n",
        "# The data is in 5 bands GRIZY, but for visualisation we use only the\n",
        "# 3 first bands and luptonize them\n",
        "def luptonize(img):\n",
        "  return make_lupton_rgb(img[:,:,2], img[:,:,1], img[:,:,0],\n",
        "                         Q=15, stretch=0.5, minimum=0)\n",
        "\n",
        "plt.figure(figsize=(10,10))\n",
        "for i, entry in enumerate(train_dset.take(25)):\n",
        "  plt.subplot(5,5,i+1)\n",
        "  plt.imshow(luptonize(entry['cutout']))\n",
        "  plt.title('z = %0.02f'%entry['specz_redshift'])\n",
        "  plt.axis('off')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "htYm8k4pEzpM"
      },
      "source": [
        "How nice is that :-) We can extract postage stamps and the corresponding spectroscopic redshift for these objects. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GqkNjWBKw_XC"
      },
      "source": [
        "# Let's collect a few examples to check their distributions\n",
        "cutouts=[]\n",
        "specz = []\n",
        "for (batch, entry) in enumerate(train_dset.take(1000)):\n",
        "  specz.append(entry['specz_redshift'])\n",
        "  cutouts.append(entry['cutout'])\n",
        "\n",
        "cutouts = np.stack(cutouts)\n",
        "specz = np.stack(specz)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ejw0Ow2wrsc"
      },
      "source": [
        "# Let's evaluate the noise standard deviation in each band, and apply range \n",
        "# compression accordingly\n",
        "from astropy.stats import mad_std\n",
        "scaling = []\n",
        "\n",
        "for i,b in enumerate(['g', 'r', 'i', 'z', 'y']):\n",
        "  plt.hist(cutouts[...,i].flatten(),100, label=b,alpha=0.5,range=[-1,1]);\n",
        "  sigma = mad_std(cutouts[...,i].flatten())\n",
        "  scaling.append(sigma)\n",
        "  plt.axvline(sigma, color='C%d'%i,alpha=0.5)\n",
        "  plt.axvline(-sigma, color='C%d'%i,alpha=0.5)\n",
        "plt.legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1gvLDqtH6QYH"
      },
      "source": [
        "# a common approach for range compression is to apply arcsinh to suppress the\n",
        "# high amplitude values\n",
        "for i,b in enumerate(['g', 'r', 'i', 'z', 'y']):\n",
        "  plt.hist(np.arcsinh(cutouts[...,i].flatten()/scaling[i]/3.),100,\n",
        "           label=b, alpha=0.5);\n",
        "plt.legend()\n",
        "plt.yscale('log')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3GYqhbkl9wQ"
      },
      "source": [
        "### Create the input pipeline\n",
        "\n",
        "Now that we know how to preprocess the data, we can build the input pipeline. Below is a function that creates a Dataset object from the tfrecords files, decode them, applies preprocessing, shuffles the dataset, and create batches of data. Finally the function returns the dataset, that Keras models can directly ingest.\n",
        "\n",
        "More information about tf.data.dataset API can be found here: \n",
        "\n",
        "https://www.tensorflow.org/guide/datasets\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "59EM2vNXLKxh"
      },
      "source": [
        "def input_fn(mode, batch_size):\n",
        "  \"\"\"\n",
        "  mode: tf.estimator.ModeKeys.TRAIN or tf.estimator.ModeKeys.EVAL\n",
        "  \"\"\"\n",
        "\n",
        "  # Using a mapping function to apply preprocessing to our data\n",
        "  def preprocessing(example):\n",
        "    img = tf.math.asinh(example['cutout'] / tf.constant(scaling) / 3. )\n",
        "    # We return the image as our input and output for a generative model\n",
        "    # We also draw some random variables for the code\n",
        "    z = tf.random.normal([batch_size, 100])\n",
        "    return z, img\n",
        "\n",
        "  if mode == tf.estimator.ModeKeys.TRAIN:\n",
        "    dataset = tf.data.Dataset.list_files('training-*')\n",
        "    dataset = dataset.interleave(tf.data.TFRecordDataset, \n",
        "                                 cycle_length=10,\n",
        "                                 num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "    dataset = dataset.repeat()\n",
        "  else:\n",
        "    dataset = tf.data.TFRecordDataset('testing-00000-of-00001')\n",
        "    \n",
        "  dataset = dataset.map(parse_example)\n",
        "  if mode == tf.estimator.ModeKeys.TRAIN:\n",
        "    dataset = dataset.shuffle(10000)\n",
        "  dataset = dataset.batch(batch_size, drop_remainder=True)\n",
        "  dataset = dataset.map(preprocessing) # Apply data preprocessing\n",
        "  dataset = dataset.prefetch(-1) # fetch next batches while training current one (-1 for autotune)\n",
        "  return dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HSC4323pMr1U"
      },
      "source": [
        "## Building a GAN architecture\n",
        "\n",
        "### Defining a generator model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZHwyt_EFy5LG"
      },
      "source": [
        "import tensorflow.compat.v1 as tf\n",
        "\n",
        "def generator_fn(noise):\n",
        "  \"\"\" Generator function, taking random noise as input and returning an image\n",
        "  \"\"\"\n",
        "  # TODO: Create a generator\n",
        "  \n",
        "  return net"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vIKQQRtL6FIF"
      },
      "source": [
        "code = tf.random.normal([1, 100])\n",
        "im = generator_fn(code)\n",
        "print(im.shape)\n",
        "imshow(im[0,:,:,0], cmap='gray'); colorbar();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZXXJTJk1636Z"
      },
      "source": [
        "### Implementing a convolutional discriminator\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VzmWj2CHzKIg"
      },
      "source": [
        "def discriminator_fn(x, unused_condition):\n",
        "\n",
        "  # TODO: Create a discriminator\n",
        "\n",
        "  return net"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_XEBfU-9Yuo"
      },
      "source": [
        "# Let's see what the discriminator thinks of our fake image:\n",
        "discriminator_fn(im, None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yk2qcOzTvfUD"
      },
      "source": [
        "## Building the GAN with TF GAN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8y_GbBuvjGK"
      },
      "source": [
        "# Build an estimator\n",
        "gan_estimator = tfgan.estimator.GANEstimator(\n",
        "    generator_fn=generator_fn,         # function implementing the generator\n",
        "    discriminator_fn=discriminator_fn, # function implementing the discriminator\n",
        "    # Loss functions for WGAN\n",
        "    generator_loss_fn=tfgan.losses.wasserstein_generator_loss,\n",
        "    discriminator_loss_fn=tfgan.losses.wasserstein_discriminator_loss,\n",
        "    # Optimizers for both models\n",
        "    generator_optimizer=tf.train.AdamOptimizer(0.001, 0.5),\n",
        "    discriminator_optimizer=tf.train.AdamOptimizer(0.0002, 0.5),\n",
        "    # Additional TF-GAN parameters\n",
        "    params={'gradient_penalty_weight':1.0},\n",
        "    # Standard Estimator confiuration\n",
        "    config=tf.estimator.RunConfig(model_dir=\"models/hsc\") # Saves checkpoints and logs in model_dir\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-p3r6UfFwaeJ"
      },
      "source": [
        "def train_input_fn():\n",
        "  return input_fn(tf.estimator.ModeKeys.TRAIN, 64)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLLL9h44veCE"
      },
      "source": [
        "gan_estimator.train(train_input_fn, \n",
        "                    max_steps=5000) # Let's train for 5000 steps"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "29lo9OXk5nFj"
      },
      "source": [
        "# Create an input pipeline for inference\n",
        "def predict_input_fn(batch_size=36):\n",
        "  def pre_process(example):\n",
        "    \"\"\" draws a random normal.\n",
        "    \"\"\"\n",
        "    z = tf.random.normal([1, 100])\n",
        "    return z\n",
        "\n",
        "  # We build an input pipeline using this preprocessing function\n",
        "  dset = tf.data.Dataset.from_tensor_slices(tf.range(0, batch_size))\n",
        "  dset = dset.map(pre_process)         # Apply the pre-processing function\n",
        "  return dset "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvDAEsjh5qW7"
      },
      "source": [
        "# Runs the input pipeline through the trained estimator\n",
        "prediction_iterable = gan_estimator.predict(predict_input_fn)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QWvY-jgf5qF9"
      },
      "source": [
        "predictions = np.array([next(prediction_iterable) for _ in range(36)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4oFqGIDV5yhP"
      },
      "source": [
        "# And let's take a look:\n",
        "tiled_image = tfgan.eval.python_image_grid(predictions, grid_shape=(6, 6))\n",
        "\n",
        "figure(figsize=(10,10))\n",
        "imshow((tiled_image[:,:,::-1][:,:,-3:]/tiled_image[:,:,:3].max()))\n",
        "axis('off');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F8iFM7R6hpfO"
      },
      "source": [
        "- Does this look ok? If so, fantastic! If not... what could be wrong....? (hint: check the range of values in real vs fake images)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-i3SsLMEKmKJ"
      },
      "source": [
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4q1HKzRp5-fX"
      },
      "source": [
        "# Start TensorBoard in notebook\n",
        "%tensorboard --logdir models"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kr-g-myt5_oX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}