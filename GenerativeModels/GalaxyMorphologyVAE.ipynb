{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ANF_DL_GalaxyGenerativeModeling.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EiffL/Tutorials/blob/master/GenerativeModels/GalaxyMorphologyVAE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YNYxkv19Bb3u"
      },
      "source": [
        "##### Copyright 2019-2020 Francois Lanusse.\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfcfTuBaBg5l"
      },
      "source": [
        "# Generative Modeling of Galaxy Images\n",
        "\n",
        "Author: [@EiffL](https://github.com/EiffL) (Francois Lanusse)\n",
        "\n",
        "### Overview\n",
        "\n",
        "In this tutorial, we learn how to combine Keras, TensorFlow Probability, and Google Colab to train a model photo-z inference in the cloud.\n",
        "\n",
        "We will be using data from the HSC Survey, and more specifically from the Public Data Release 2, which can be found here: https://hsc-release.mtk.nao.ac.jp/doc/\n",
        "\n",
        "\n",
        "The dataset contains postage stamps of galaxies in 5 HSC bands, along with corresponding spectroscopic redshifts.\n",
        "\n",
        "Our goal will be to estimate redshift just by looking at a picture of a galaxy.\n",
        "\n",
        "### Learning objectives\n",
        "\n",
        "In this notebook, we will learn how to:\n",
        "*   Build a tf.data.Dataset input pipeline.\n",
        "*   Build a simple convolutional neural network with Keras.\n",
        "*   Train a model on GPUs in the cloud.\n",
        "*   (Stretch Goal) Use TensorFlow Probability to make a probabilistic model.\n",
        "\n",
        "Note: this Tutorial was originaly presented at [Astro Hack Week 2019](https://github.com/AstroHackWeek/AstroHackWeek2019/tree/master/day4_bayesiandeep).\n",
        "\n",
        "### Instructions for enabling GPU access\n",
        "\n",
        "By default, notebooks are started without acceleration. To make sure that the runtime is configured for using GPUs, go to `Runtime > Change runtime type`, and select GPU in `Hardware Accelerator`.\n",
        "\n",
        "\n",
        "\n",
        "### Installs and Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5XIcKLGBE33"
      },
      "source": [
        "import os\n",
        "import re\n",
        "import time\n",
        "import json\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OGBGfUdSF7QH"
      },
      "source": [
        "### Checking for GPU access"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jgs_ONXTF6vX"
      },
      "source": [
        "#Checking for GPU access\n",
        "if tf.test.gpu_device_name() != '/device:GPU:0':\n",
        "  print('WARNING: GPU device not found.')\n",
        "else:\n",
        "  print('SUCCESS: Found GPU: {}'.format(tf.test.gpu_device_name()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "97CFtkkqFv5P"
      },
      "source": [
        "## Downloading the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q4VyE8QmJEGh"
      },
      "source": [
        "# Google Cloud Storage bucket for Estimator logs and storing\n",
        "# the training dataset.\n",
        "bucket = 'ahw2019' # Bucket setup for this AHW2019 tutorial\n",
        "print('Using bucket: {}'.format(bucket))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57gH9b7RPWzu"
      },
      "source": [
        "# Retrieve the catalogs\n",
        "!gsutil -m cp gs://{bucket}/hsc_photoz/cat2/catalog_*.fits .\n",
        "!gsutil -m cp gs://{bucket}/hsc_photoz/tfrecords2/* ."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OGENy38rPn1s"
      },
      "source": [
        "from astropy.table import Table\n",
        "cat_train = Table.read('catalog_train.fits')\n",
        "cat_test = Table.read('catalog_test.fits')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3HRAxSC_JS3R"
      },
      "source": [
        "## Building a tf.data.Dataset Input Pipeline\n",
        "\n",
        "The first step is to read the data from the tfrecords format on disk into a tf.data.Dataset. This TensorFlow API is the canonical way to supply data to a model during training. It is fast and optimized, and supports distributed training!\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s2Nznh3aJSXa"
      },
      "source": [
        "# The data is saved as a TFRecord, needs to get parsed and turned into a dataset\n",
        "dset = tf.data.TFRecordDataset(['training-%05d-of-00010'%i for i in range(10)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JKfKNgEeNTuE"
      },
      "source": [
        "# To extract one example from the TFRecord, we can use the following syntax:\n",
        "for i in dset.take(1):\n",
        "  print(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8t0nLpgfDzV2"
      },
      "source": [
        "The data is currently stored in a serialized format, as strings. We need to decode it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yhPgF33ZOK7m"
      },
      "source": [
        "img_len = 64\n",
        "num_bands = 5\n",
        "\n",
        "# This function defines the operations to apply to a serialized example to\n",
        "# turn it back into a dictionary object\n",
        "def parse_example(example):\n",
        "\n",
        "  # First, let's define what fields we are expecting\n",
        "  data_fields = {\n",
        "      \"image/encoded\": tf.io.FixedLenFeature((), tf.string),\n",
        "      \"image/format\": tf.io.FixedLenFeature((), tf.string),\n",
        "      \"id\": tf.io.FixedLenFeature((), tf.int64)\n",
        "  }\n",
        "  for k in cat_train.colnames[5:]:\n",
        "    data_fields['attrs/'+k] = tf.io.FixedLenFeature([], tf.float32)\n",
        "\n",
        "  parsed_example = tf.io.parse_single_example(example, data_fields)\n",
        "\n",
        "  # Decode the image from string format\n",
        "  cutout = tf.io.decode_raw(parsed_example['image/encoded'], out_type=tf.float32) \n",
        "  cutout = tf.reshape(cutout, [img_len, img_len, num_bands])\n",
        "\n",
        "  # Outputs results as a dictionary\n",
        "  output_dict = {\"cutout\": cutout}\n",
        "  for k in cat_train.colnames[5:]:\n",
        "    output_dict[k] = parsed_example['attrs/'+k]\n",
        "\n",
        "  return output_dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VzMcHlasEMvF"
      },
      "source": [
        "With this decoding function defined, we can apply it to the dataset by using the dataset.map() method:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZIBewKf0ELN-"
      },
      "source": [
        "train_dset = dset.map(parse_example)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mbi4bL21EMED"
      },
      "source": [
        "Let's have a look at the content of this new dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IHcy8OgQTQMW"
      },
      "source": [
        "for i in train_dset.take(1):\n",
        "  print(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cVBQKpT7EhDa"
      },
      "source": [
        "Now our dataset is decoded into numbers and arrays."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_YYlkH3dLm_2"
      },
      "source": [
        "### Dataset preprocessing\n",
        "\n",
        "An important step of any input pipeline is to make\n",
        "sure the data is reasonably well behaved before \n",
        "feeding to the neural network. Here are some common strategies:\n",
        "\n",
        "\n",
        "*   Apply log() to values with large dynamic range\n",
        "*   Remove means, and standardize standard deviation\n",
        "*   etc...\n",
        "\n",
        "\n",
        "So, we begin by looking at our data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yHIKuq5OMa7E"
      },
      "source": [
        "# What's in our dataset:\n",
        "train_dset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9PRSqauJTt5f"
      },
      "source": [
        "Ok, we see that this dataset is a dictionary, field `inputs` are hsc cutouts in 5 bands (g,r,i,z,y), this will be the inputs to our CNN. We also see a `specz_redshift` entry, that will be our prediction target. Let's have a look at these."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xm0ifpc4VrYc"
      },
      "source": [
        "from astropy.visualization import make_lupton_rgb\n",
        "%pylab inline \n",
        "\n",
        "# The data is in 5 bands GRIZY, but for visualisation we use only the\n",
        "# 3 first bands and luptonize them\n",
        "def luptonize(img):\n",
        "  return make_lupton_rgb(img[:,:,2], img[:,:,1], img[:,:,0],\n",
        "                         Q=15, stretch=0.5, minimum=0)\n",
        "\n",
        "plt.figure(figsize=(10,10))\n",
        "for i, entry in enumerate(train_dset.take(25)):\n",
        "  plt.subplot(5,5,i+1)\n",
        "  plt.imshow(luptonize(entry['cutout']))\n",
        "  plt.title('z = %0.02f'%entry['specz_redshift'])\n",
        "  plt.axis('off')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "htYm8k4pEzpM"
      },
      "source": [
        "How nice is that :-) We can extract postage stamps and the corresponding spectroscopic redshift for these objects. \n",
        "\n",
        "Before doing anything else, we should take a closer look at the  data and check that it's well behaved."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-c7o1B4Ma4X"
      },
      "source": [
        "# Let's collect a few examples to check their distributions\n",
        "cutouts=[]\n",
        "specz = []\n",
        "for (batch, entry) in enumerate(train_dset.take(1000)):\n",
        "  specz.append(entry['specz_redshift'])\n",
        "  cutouts.append(entry['cutout'])\n",
        "\n",
        "cutouts = np.stack(cutouts)\n",
        "specz = np.stack(specz)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBxLT8tfaRBK"
      },
      "source": [
        "for i,b in enumerate(['g', 'r', 'i', 'z', 'y']):\n",
        "  plt.hist(cutouts[...,i].flatten(),100, label=b);\n",
        "plt.legend()\n",
        "\n",
        "# Problem ?"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bXkCgSHc2gBR"
      },
      "source": [
        "Do you see a problem in this histogram?\n",
        "\n",
        "Let's have a look at a few images:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ECvEJL_UlZ2Q"
      },
      "source": [
        "plt.figure(figsize=(15,3))\n",
        "for i,b in enumerate(['g', 'r', 'i', 'z', 'y']):\n",
        "  plt.subplot(1,5,i+1)\n",
        "  plt.imshow(cutouts[0,:,:,i],vmin=-1,vmax=50)\n",
        "  plt.title(b)\n",
        "  plt.axis('off')\n",
        "\n",
        "plt.figure(figsize=(15,3))\n",
        "for i,b in enumerate(['g', 'r', 'i', 'z', 'y']):\n",
        "  plt.subplot(1,5,i+1)\n",
        "  plt.imshow(cutouts[1,:,:,i],vmin=-1,vmax=50)\n",
        "  plt.title(b)\n",
        "  plt.axis('off')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KGZbzaOQ2w_m"
      },
      "source": [
        "In the plot above, each row is a different galaxy, and each column is a different band."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mxhBE7xAbGpM"
      },
      "source": [
        "# Let's look at it in log scale\n",
        "for i,b in enumerate(['g', 'r', 'i', 'z', 'y']):\n",
        "  plt.hist(cutouts[...,i].flatten(),100, label=b,alpha=0.5);\n",
        "plt.legend()\n",
        "plt.yscale('log')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6XwYxVLfbpnK"
      },
      "source": [
        "This is terrible, the tail of this distribution in pixel intensity is going to kill our neural networks. We need to standardize the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YWu_s273cqUL"
      },
      "source": [
        "# Let's evaluate the noise standard deviation in each band, and apply range \n",
        "# compression accordingly\n",
        "from astropy.stats import mad_std\n",
        "scaling = []\n",
        "\n",
        "for i,b in enumerate(['g', 'r', 'i', 'z', 'y']):\n",
        "  plt.hist(cutouts[...,i].flatten(),100, label=b,alpha=0.5,range=[-1,1]);\n",
        "  sigma = mad_std(cutouts[...,i].flatten())\n",
        "  scaling.append(sigma)\n",
        "  plt.axvline(sigma, color='C%d'%i,alpha=0.5)\n",
        "  plt.axvline(-sigma, color='C%d'%i,alpha=0.5)\n",
        "plt.legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5asq6mhLeWAK"
      },
      "source": [
        "# Let's have a look at this distribution if we rescale each band by the standard\n",
        "# deviation\n",
        "for i,b in enumerate(['g', 'r', 'i', 'z', 'y']):\n",
        "  plt.hist(cutouts[...,i].flatten()/scaling[i],100, label=b,alpha=0.5,\n",
        "           range=[-10,10]);\n",
        "legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RzE7J3AMgaj1"
      },
      "source": [
        "Sweet! Now there is still an unsigthly tail towards very large values. We are going to apply range compression to get rid of it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJCS-zMsboOD"
      },
      "source": [
        "# a common approach for range compression is to apply arcsinh to suppress the\n",
        "# high amplitude values\n",
        "for i,b in enumerate(['g', 'r', 'i', 'z', 'y']):\n",
        "  plt.hist(np.arcsinh(cutouts[...,i].flatten()/scaling[i]/3),100,\n",
        "           label=b, alpha=0.5);\n",
        "plt.legend()\n",
        "plt.yscale('log')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KrSqabqBgtS4"
      },
      "source": [
        "![Perfection](https://i.kym-cdn.com/entries/icons/original/000/022/900/704.jpg)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jb_TCsVDfMzH"
      },
      "source": [
        "# we can have a look at individual postage stamps with or without this scaling\n",
        "subplot(121)\n",
        "imshow(cutouts[0,:,:,1]/scaling[1])\n",
        "title('Before')\n",
        "subplot(122)\n",
        "imshow(np.arcsinh(cutouts[0,:,:,1]/scaling[1]/3))\n",
        "title('After');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G5Az8G5YhtXj"
      },
      "source": [
        "# Let's just check the specz values\n",
        "plt.hist(specz,100);\n",
        "# Should be ok"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "azewX3L8F4fH"
      },
      "source": [
        "Now that we have defined a scaling for the data that should be appropriate, we can build a scaling function and apply it to the dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N64jVDeFhtdm"
      },
      "source": [
        "# Using a mapping function to apply preprocessing to our data\n",
        "def preprocessing(example):\n",
        "  def range_compression(img):\n",
        "    return tf.math.asinh(img / tf.constant(scaling) / 3. )\n",
        "  # Our preprocessing function only returns the postage stamps, and the specz\n",
        "  return range_compression(example['cutout']), example['specz_redshift']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9PigT6tEhtga"
      },
      "source": [
        "dset = train_dset.map(preprocessing)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u7k9_qgzhtjk"
      },
      "source": [
        "# Let's draw some examples from this  now\n",
        "cutouts=[]\n",
        "specz = []\n",
        "for (batch, entry) in enumerate(dset.take(1000)):\n",
        "  specz.append(entry[1])\n",
        "  cutouts.append(entry[0])\n",
        "\n",
        "cutouts = np.stack(cutouts)\n",
        "specz = np.stack(specz)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r3myN4MnkW8Z"
      },
      "source": [
        "for i,b in enumerate(['g', 'r', 'i', 'z', 'y']):\n",
        "  plt.hist(cutouts[...,i].flatten(),100, label=b,alpha=0.5, range=[-1,6]);\n",
        "plt.legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dgu9NKgnMajT"
      },
      "source": [
        "plt.figure(figsize=(15,3))\n",
        "for i,b in enumerate(['g', 'r', 'i', 'z', 'y']):\n",
        "  plt.subplot(1,5,i+1)\n",
        "  plt.imshow(cutouts[0,:,:,i],vmin=-1,vmax=6)\n",
        "  plt.title(b)\n",
        "  plt.axis('off')\n",
        "\n",
        "plt.figure(figsize=(15,3))\n",
        "for i,b in enumerate(['g', 'r', 'i', 'z', 'y']):\n",
        "  plt.subplot(1,5,i+1)\n",
        "  plt.imshow(cutouts[1,:,:,i],vmin=-1,vmax=6)\n",
        "  plt.title(b)\n",
        "  plt.axis('off')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTDy-MGVNKtF"
      },
      "source": [
        "mad_std(cutouts[0,:,:,0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dXJVuvWmkZF7"
      },
      "source": [
        "Sweeeeeet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3GYqhbkl9wQ"
      },
      "source": [
        "### Create the input pipeline\n",
        "\n",
        "Now that we know how to preprocess the data, we can build the input pipeline. Below is a function that creates a Dataset object from the tfrecords files, decode them, applies preprocessing, shuffles the dataset, and create batches of data. Finally the function returns the dataset, that Keras models can directly ingest.\n",
        "\n",
        "More information about tf.data.dataset API can be found here: \n",
        "\n",
        "https://www.tensorflow.org/guide/datasets\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "59EM2vNXLKxh"
      },
      "source": [
        "# Using a mapping function to apply preprocessing to our data\n",
        "def preprocessing(example):\n",
        "  img = tf.math.asinh(example['cutout'] / tf.constant(scaling) / 3. )\n",
        "  # We return the image as our input and output for a generative model\n",
        "  return img, img\n",
        "\n",
        "def input_fn(mode, batch_size):\n",
        "  \"\"\"\n",
        "  mode: tf.estimator.ModeKeys.TRAIN or tf.estimator.ModeKeys.EVAL\n",
        "  \"\"\"\n",
        "  if mode == tf.estimator.ModeKeys.TRAIN:\n",
        "    dataset = tf.data.Dataset.list_files('training-*')\n",
        "    dataset = dataset.interleave(tf.data.TFRecordDataset, \n",
        "                                 cycle_length=10,\n",
        "                                 num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "    dataset = dataset.repeat()\n",
        "  else:\n",
        "    dataset = tf.data.TFRecordDataset('testing-00000-of-00001')\n",
        "  \n",
        "  # At this point, dataset contains raw tfrecords\n",
        "\n",
        "  # TODO: add a dataset.map() to parse the example\n",
        "  dataset = #....\n",
        "  if mode == tf.estimator.ModeKeys.TRAIN:\n",
        "    # TODO: shuffle the dataset with a buffer size of 10000\n",
        "    dataset = #....\n",
        "  # TODO: batch the dataset to make batches of size `batch_size`. \n",
        "  # Use the `drop_remainder=True` option of tf.data.dataset.batch() to avoid problems\n",
        "  # when the size of the dataset is not a multiple of batch_size\n",
        "  dataset = #.... \n",
        "  # TODO: Apply the `preprocessing` function to the dataset\n",
        "  dataset = #.... \n",
        "  dataset = dataset.prefetch(-1) # fetch next batches while training current one (-1 for autotune)\n",
        "  return dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGty-Yi1fy8s"
      },
      "source": [
        "To make sure that your input function works, try sampling a batch from it:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bzd1vh8uf4pQ"
      },
      "source": [
        "dset = input_fn(tf.estimator.ModeKeys.TRAIN, 25)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sHDIvFt-f_N3"
      },
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "for batch in dset.take(1):\n",
        "  plt.subplot(5,5,i+1)\n",
        "  plt.imshow(batch[0][i,:,:,0])\n",
        "  plt.axis('off')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HSC4323pMr1U"
      },
      "source": [
        "## Building a VAE with Keras\n",
        "\n",
        "Now that have access to training data, let's build a small Variational Auto-Encoder to try to learn how to sample galaxy images.\n",
        "\n",
        "### Defining a recognition model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z34AABDI5OmZ"
      },
      "source": [
        "import tensorflow_probability as tfp\n",
        "tfpl = tfp.layers\n",
        "tfkl = tf.keras.layers\n",
        "tfd = tfp.distributions\n",
        "\n",
        "def get_probabilistic_encoder(latent_dim=32):\n",
        "  \"\"\" Creates a small convolutional encoder for the requested latent dimension\n",
        "  \"\"\"\n",
        "  # We choose a prior distribution for the latent codes\n",
        "  prior = tfd.MultivariateNormalDiag(loc=tf.zeros(latent_dim))\n",
        "\n",
        "  return tf.keras.Sequential([ \n",
        "            # TODO: Write a recognition model.\n",
        "            # Remember, the output needs to be a distribution, and needs to include \n",
        "            # the KL regularisation term\n",
        "      ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vIKQQRtL6FIF"
      },
      "source": [
        "prob_encoder = get_probabilistic_encoder(latent_dim=32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4HS0kGdT6FMN"
      },
      "source": [
        "prob_encoder.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6PFBC95S6FFL"
      },
      "source": [
        "for batch_im, batch_target in dset.take(1): # Sample only one batch of images\n",
        "  batch_encoded = prob_encoder(batch_im)    # Apply the encoder on images "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o5uN7-th6z7t"
      },
      "source": [
        "batch_encoded"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZXXJTJk1636Z"
      },
      "source": [
        "### Implementing a generator\n",
        "\n",
        "One of the important considerations for the generator is, what likelihood to use.\n",
        "\n",
        "Contrary to an MNIST example, we are dealing here with continuous images, with Gaussian noise, we will therefore choose to use a Gaussian likelihood at the output of the generator."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5QR0ZU3P7zAR"
      },
      "source": [
        "def get_probabilistic_decoder(latent_dim=32):\n",
        "  \"\"\" Creates a small convolutional decoder for the requested latent dimension\n",
        "  \"\"\"\n",
        "  return tf.keras.Sequential([\n",
        "      # TODO: Write a decoder \n",
        "      \n",
        "      # .....\n",
        "\n",
        "      # This will be the output distribution layer that defines the likelihood\n",
        "      # Note that we set sigma=0.3 which is around the standard deviation of the \n",
        "      # noise in the images after our preprocessing\n",
        "      tfpl.DistributionLambda(lambda t: tfd.MultivariateNormalDiag(loc=t,\n",
        "                                              scale_identity_multiplier=0.3))\n",
        "  ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_XEBfU-9Yuo"
      },
      "source": [
        "# Let's instantiate the decoder\n",
        "prob_decoder = get_probabilistic_decoder(latent_dim=32)\n",
        "# And check its summary\n",
        "prob_decoder.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4fWy0WxH9ZBN"
      },
      "source": [
        "# Draw a radom sample of the code\n",
        "code_sample = batch_encoded.sample()\n",
        "# And decode that sample\n",
        "decoded_im = prob_decoder(code_sample)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XtHiQLsw92Dg"
      },
      "source": [
        "decoded_im"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l6yEUKML96mq"
      },
      "source": [
        "figure(figsize=(9,3))\n",
        "subplot(131)\n",
        "imshow(batch_im[0,:,:,0],cmap='gray'); axis('off')\n",
        "title(\"Input Image\")\n",
        "subplot(132)\n",
        "imshow(decoded_im.sample()[0,:,:,0],cmap='gray'); axis('off')\n",
        "title(\"Sample from generator output\")\n",
        "subplot(133)\n",
        "imshow(decoded_im.mean()[0,:,:,0],cmap='gray'); axis('off')\n",
        "title(\"Mean of generator output\");"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KcVTpgEX-Jxu"
      },
      "source": [
        "### Building the VAE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-wDl8iad-IBC"
      },
      "source": [
        "vae = tf.keras.Sequential([\n",
        "          tfkl.InputLayer([64,64,5]),\n",
        "          prob_encoder,\n",
        "          prob_decoder])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8HSHux6J-Prh"
      },
      "source": [
        "vae.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zFo4wzG-RoZ"
      },
      "source": [
        "# We define the reconstruction loss as the negative log likelihood\n",
        "negloglik = lambda x, rv_x: -rv_x.log_prob(x)\n",
        "# And use it to compile the VAE\n",
        "vae.compile(optimizer=tf.optimizers.Adam(learning_rate=1e-3),\n",
        "            loss=negloglik)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQXCdLVkUEzn"
      },
      "source": [
        "# We define the batch size\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# Learning rate schedule\n",
        "LEARNING_RATE=0.001\n",
        "LEARNING_RATE_EXP_DECAY=0.9\n",
        "\n",
        "lr_decay = tf.keras.callbacks.LearningRateScheduler(\n",
        "    lambda epoch: LEARNING_RATE * LEARNING_RATE_EXP_DECAY**epoch,\n",
        "    verbose=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LgppIA1sdZe6"
      },
      "source": [
        "# We actually create our training dataset with our input function\n",
        "dataset_training = input_fn(tf.estimator.ModeKeys.TRAIN, BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1mgZfTZc7zIO"
      },
      "source": [
        "# We are ready to train our model\n",
        "history = vae.fit(dataset_training,\n",
        "            steps_per_epoch=20000//BATCH_SIZE, \n",
        "            epochs=15,\n",
        "            callbacks=[lr_decay])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-90WigOEIIpM"
      },
      "source": [
        "### Testing VAE auto-encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oNrIw7y74uEL"
      },
      "source": [
        "# Now that the model is 'trained', we can apply it\n",
        "dataset_eval = input_fn(tf.estimator.ModeKeys.EVAL, BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lG22cuAkCLXF"
      },
      "source": [
        "for batch_im, batch_targets in dataset_eval.take(1):\n",
        "  # This extracts one batch of the test dset and shows the first example\n",
        "  imshow((batch_im[3,:,:,::-1][:,:,-3:]/batch_im[3,:,:,:3].numpy().max()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MD5L1K4gCBxp"
      },
      "source": [
        "autoencoded_im = vae(batch_im) # Run the input batch through the model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PrdAenDnlDmC"
      },
      "source": [
        "subplot(121)\n",
        "# Plot the mean of the output Bernoulli distribution\n",
        "imshow(autoencoded_im.mean()[3,:,:,-3:]/autoencoded_im.mean()[3,:,:,-3:].numpy().max(),cmap='gray'); axis('off'); \n",
        "title('Mean output')\n",
        "subplot(122)\n",
        "# Plot a random sample of the output Bernoulli distribution\n",
        "imshow(autoencoded_im.sample()[3,:,:,0],cmap='gray'); axis('off');\n",
        "title('Sample output');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ve86cLkcIN5v"
      },
      "source": [
        "### Sampling from the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ho45ddXjJS6d"
      },
      "source": [
        "latent_samples = tfd.MultivariateNormalDiag(loc=tf.zeros(32)).sample(16)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-6uI4_AnIX8n"
      },
      "source": [
        "image_samples = prob_decoder(0.5*latent_samples)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xncNdQ3AIZl4"
      },
      "source": [
        "figure(figsize=(10,10))\n",
        "fig = image_samples.mean().numpy().reshape((4,4,64,64,5))\n",
        "fig = fig.transpose((0,2,1,3,4)).reshape((4*64,4*64,5))\n",
        "# Let's see the result\n",
        "imshow(fig[:,:,::-1][:,:,-3:]/(fig[:,:,::-1][:,:,-3:]).max()); axis('off');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-i3SsLMEKmKJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}